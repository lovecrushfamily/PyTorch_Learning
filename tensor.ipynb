{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tensor Fundamentals\n",
    "\n",
    "- Pytorch is an open source machine learning and deep learning framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "1. Tensors are fundamental building block of machine learning\n",
    "2. Tensor is kind of multi-dimensional array like numpy array but run on GPU instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar (0-dimensional tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_scalar = torch.tensor(16)\n",
    "tensor_scalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the dimension of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the number within a tensor (only work for 0-dimensional tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensor item: 16'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Tensor item: {tensor_scalar.item()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector (1-dimensional tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0]), 'Tensor dimension: 1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_vector = torch.tensor([0,3,7,9,1,2,0,7,3,0])\n",
    "\n",
    "tensor_vector, f\"Tensor dimension: {tensor_vector.ndim}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the shape of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shape of tensor vector : torch.Size([10])'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Shape of tensor vector : {tensor_vector.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix (2-dimensional tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "        [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "        [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX = torch.tensor([[0,3,7,9,1,2,0,7,3,0],\n",
    "                              [0,9,8,1,3,2,5,7,9,2],\n",
    "                              [0,3,7,6,1,1,7,1,4,8]])\n",
    "\n",
    "TENSOR_MATRIX\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shape of the matrix: torch.Size([3, 10])'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Shape of the matrix: {TENSOR_MATRIX.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor (multiple-dimensional tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  16,   10, 2004],\n",
       "         [   9,    3, 1986],\n",
       "         [   3,   12, 2007],\n",
       "         [  20,    7, 2010],\n",
       "         [   4,    1, 2004]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[[16,10,2004],\n",
    "                        [9,3,1986],\n",
    "                        [3,12,2007],\n",
    "                        [20,7,2010],\n",
    "                        [4,1,2004]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensor shape: torch.Size([1, 5, 3])'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Tensor shape: {tensor.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensor dim: 3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Tensor dim: {tensor.ndim}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8818, 0.8782, 0.5274],\n",
       "         [0.0297, 0.1434, 0.1137],\n",
       "         [0.6546, 0.0778, 0.9789],\n",
       "         ...,\n",
       "         [0.2149, 0.2187, 0.6186],\n",
       "         [0.9234, 0.3978, 0.9917],\n",
       "         [0.5657, 0.5665, 0.3220]],\n",
       "\n",
       "        [[0.6868, 0.8504, 0.2323],\n",
       "         [0.5756, 0.6202, 0.2531],\n",
       "         [0.7907, 0.7920, 0.8056],\n",
       "         ...,\n",
       "         [0.7767, 0.5080, 0.9974],\n",
       "         [0.9311, 0.9186, 0.9114],\n",
       "         [0.2134, 0.7985, 0.4693]],\n",
       "\n",
       "        [[0.7710, 0.2053, 0.3264],\n",
       "         [0.6850, 0.7437, 0.1260],\n",
       "         [0.5273, 0.4716, 0.3857],\n",
       "         ...,\n",
       "         [0.0377, 0.9513, 0.8071],\n",
       "         [0.7844, 0.4371, 0.5309],\n",
       "         [0.5304, 0.2954, 0.5497]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6066, 0.9043, 0.2323],\n",
       "         [0.7661, 0.0326, 0.0672],\n",
       "         [0.5854, 0.9981, 0.7584],\n",
       "         ...,\n",
       "         [0.4233, 0.3866, 0.3680],\n",
       "         [0.0923, 0.3519, 0.2337],\n",
       "         [0.2013, 0.1656, 0.1025]],\n",
       "\n",
       "        [[0.5125, 0.1353, 0.6573],\n",
       "         [0.3599, 0.1362, 0.1065],\n",
       "         [0.8623, 0.5951, 0.4546],\n",
       "         ...,\n",
       "         [0.9423, 0.7667, 0.3810],\n",
       "         [0.8867, 0.9491, 0.3651],\n",
       "         [0.2073, 0.4446, 0.1647]],\n",
       "\n",
       "        [[0.7868, 0.3538, 0.8310],\n",
       "         [0.5671, 0.7389, 0.2060],\n",
       "         [0.4691, 0.1584, 0.1725],\n",
       "         ...,\n",
       "         [0.7182, 0.8791, 0.0578],\n",
       "         [0.4713, 0.2840, 0.5347],\n",
       "         [0.7185, 0.9631, 0.5140]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran_tensor = torch.rand(size=(224,224,3)) # ([height, width, color_channels])\n",
    "ran_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shape of ran tensor : torch.Size([224, 224, 3]) and tensor dimension: 3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Shape of ran tensor : {ran_tensor.shape} and tensor dimension: {ran_tensor.ndim}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Shuffle tensor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor = torch.zeros(size=(1,6), dtype=torch.int32)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]], dtype=torch.int16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_tensor = torch.ones(size=(2,4), dtype=torch.int16)\n",
    "one_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor within a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_tensor = torch.arange(2,30, 2) #  torch.arrange(start, end, step)\n",
    "range_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros_like and Ones_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn any tensor into zeros tensor.\n",
    "zeros_like_tensor = torch.zeros_like(input=range_tensor)\n",
    "\n",
    "zeros_like_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same effect \n",
    "zero_tensor = torch.zeros(size=range_tensor.shape, dtype=torch.float32)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting information of a tensor\n",
    "\n",
    "- shape - What shape is the tensor? (some operations requires specific rules)\n",
    "- dtype - What datatype are the elements within the tensor stored in\n",
    "- device - What device is the tensor stored on? (usually GPU or CPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Shape: torch.Size([14])', 'Data type: torch.int64', 'Device: cpu')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Shape: {range_tensor.shape}\", f\"Data type: {range_tensor.dtype}\", f\"Device: {range_tensor.device}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Tensor (Operations)\n",
    "\n",
    "- *Scalar Operations*\n",
    "\n",
    "- *Matrix Operations*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  16,   10, 2004],\n",
       "         [   9,    3, 1986],\n",
       "         [   3,   12, 2007],\n",
       "         [  20,    7, 2010],\n",
       "         [   4,    1, 2004]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Addition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 116,  110, 2104],\n",
       "         [ 109,  103, 2086],\n",
       "         [ 103,  112, 2107],\n",
       "         [ 120,  107, 2110],\n",
       "         [ 104,  101, 2104]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Subtraction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -84,  -90, 1904],\n",
       "         [ -91,  -97, 1886],\n",
       "         [ -97,  -88, 1907],\n",
       "         [ -80,  -93, 1910],\n",
       "         [ -96,  -99, 1904]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Multiplication*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1600,   1000, 200400],\n",
       "         [   900,    300, 198600],\n",
       "         [   300,   1200, 200700],\n",
       "         [  2000,    700, 201000],\n",
       "         [   400,    100, 200400]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Division*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.0000e+00, 2.5000e+00, 5.0100e+02],\n",
       "         [2.2500e+00, 7.5000e-01, 4.9650e+02],\n",
       "         [7.5000e-01, 3.0000e+00, 5.0175e+02],\n",
       "         [5.0000e+00, 1.7500e+00, 5.0250e+02],\n",
       "         [1.0000e+00, 2.5000e-01, 5.0100e+02]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Matrix Multiplication*\n",
    "\n",
    "Rules for matrix multiplication\n",
    "\n",
    "1. The **inner dimensions** must match\n",
    "\n",
    "        (3, 2) @ (3, 2) ->  Won't work\n",
    "        (2, 3) @ (3, 2) -> Will work\n",
    "        (3, 2) @ (2, 3) -> Will work\n",
    "\n",
    "2. The resulting matrix has the shape of the **Outer dimension**\n",
    "        \n",
    "        (2, 3) @ (3, 2) = (2, 2)\n",
    "        (3, 2) @ (2, 3) = (3, 3)\n",
    "\n",
    "\n",
    "\n",
    "*Note: \"**@**\" in Python is the symbol for both matrix multiplication notation and for programming syntax*.\n",
    "\n",
    "Other way to perform matrix multiplication:\n",
    "- **torch.matmul()**\n",
    "- **Tensor.matmul()**\n",
    "\n",
    "*Matrix multiplication like this is also referred to as the **dot product** of two matrices*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3216, 0.7157],\n",
       "         [0.0400, 0.8578],\n",
       "         [0.7680, 0.9590]]),\n",
       " '^',\n",
       " tensor([[0.0736, 0.8598, 0.7692],\n",
       "         [0.8741, 0.9378, 0.6995]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tensor_2x3 = torch.rand(size=(2,3))\n",
    "tensor_3x2 = torch.rand(size=(3,2))\n",
    "\n",
    "tensor_3x2, \"^\", tensor_2x3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6488, 1.5278],\n",
       "        [0.8559, 2.1008]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2,3) @ (3,2) -> (2,2)\n",
    "tensor_2x3 @ tensor_3x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6492, 0.9477, 0.7480],\n",
       "        [0.7527, 0.8388, 0.6308],\n",
       "        [0.8948, 1.5597, 1.2616]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3,2) @ (2,3) -> (3,3)\n",
    "tensor_3x2 @ tensor_2x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Element-wise multiplication*\n",
    "\n",
    "-  Suppose **s** and **t** are two vectors of the **same dimension**. Then we use **s ⊙ t** to denote the element-wise product of the two vectors. \n",
    "\n",
    "        [1 2] ⊙ [3 4] = [1x3  2x4] = [3 8]      -> Mathematical Notation \n",
    "        [1 2] * [3 4] = [1x3  2x4] = [3 8]      -> Programming Syntax\n",
    "\n",
    "*Element-wise multiplication is sometimes called the **Hadamard product** or **Schur product**, applied the same rule as matrix Addition, Subtraction*\n",
    "\n",
    "*This rule of same size applied for all kind of tensor*\n",
    "\n",
    "**Element-wise multiplication != Matrix multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  9, 49, 81,  1,  4,  0, 49,  9,  0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_vector * tensor_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Matrix Addition, Subtraction, Division*\n",
    "\n",
    "**Rule:**\n",
    "- The matrices are using for these kind of operators must be in the same size(shape)\n",
    "\n",
    "*These rule are applied for Matrix Subtraction, Division also*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3953, 0.8998, 1.5372],\n",
       "         [1.5897, 1.7956, 1.6585]]),\n",
       " '^',\n",
       " tensor([[-0.2480,  0.8198,  0.0011],\n",
       "         [ 0.1584,  0.0800, -0.2595]]),\n",
       " '^',\n",
       " tensor([[ 0.2289, 21.4843,  1.0015],\n",
       "         [ 1.2213,  1.0933,  0.7294]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2x3 + tensor_3x2.T, \"^\", tensor_2x3 - tensor_3x2.T ,\"^\", tensor_2x3 / tensor_3x2.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *0-dimensional tensor transpose is deprecated*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1-dimensional tensor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14707/367959955.py:2: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647329220/work/aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  tensor_vector.T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After transpose => the same as the original => unnecessary to transpose\n",
    "tensor_vector.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2-dimensional tensor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "        [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "        [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [3, 9, 3],\n",
       "        [7, 8, 7],\n",
       "        [9, 1, 6],\n",
       "        [1, 3, 1],\n",
       "        [2, 2, 1],\n",
       "        [0, 5, 7],\n",
       "        [7, 7, 1],\n",
       "        [3, 9, 4],\n",
       "        [0, 2, 8]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX.T     # => Prefer using this syntax for matrix => easy to understand and interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *3-dimensional tensor*\n",
    "\n",
    "**I got it:**\n",
    "\n",
    "- *transpose mean that you indirectly reshape the matrix or the tensor, but in a simple way, that you just rearrange, swap the dimension of a tensor without redefine it, that's it*\n",
    "\n",
    "        tensor.transpose(0,1) => swap the 0th dim to the 1th dim => \n",
    "        tensor.transpose(0,2) => swap the 0th dim to the 2th dim => tensor.T    (short-hand syntax)\n",
    "        tensor.transpose(1,2) => swap the 1th dim to the 2th dim => tensor.mT \n",
    "\n",
    "*There're much more things to play when we deal with higher multi-dimensional tensors, stay tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  16,   10, 2004],\n",
       "          [   9,    3, 1986],\n",
       "          [   3,   12, 2007],\n",
       "          [  20,    7, 2010],\n",
       "          [   4,    1, 2004]]]),\n",
       " '^',\n",
       " torch.Size([1, 5, 3]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor, \"^\", tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1, 3]),\n",
       " '^',\n",
       " torch.Size([3, 5, 1]),\n",
       " '^',\n",
       " torch.Size([1, 3, 5]),\n",
       " '^')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.transpose(0,1).shape, \"^\",\\\n",
    "tensor.transpose(0,2).shape, \"^\",\\\n",
    "tensor.transpose(1,2).shape, \"^\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "- min\n",
    "- max\n",
    "- mean\n",
    "- sum\n",
    "\n",
    "*Apply for all kind of tensor*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Min*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Minimum of tensor: 0', tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Minimum of tensor: {tensor_vector.min()}\", tensor_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Max*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Maximum of tensor: 9', tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Maximum of tensor: {tensor_vector.max()}\", tensor_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Mean*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mean of tensor: 3.200000047683716', tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Mean of tensor: {tensor_vector.type(torch.float32).mean()}\", tensor_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Sum*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mean of tensor: 32', tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Mean of tensor: {tensor_vector.sum()}\", tensor_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Aggregation\n",
    "\n",
    "- argmax()\n",
    "- argmin()\n",
    "\n",
    "*Return the single index value of the max or min value in the tensor has already flatten, regardless of that tensor's dimension*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Argmax()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensor: [0, 3, 7, 9, 1, 2, 0, 7, 3, 0] has the maximum value is 9 at index 3'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Tensor: {tensor_vector.tolist()} has the maximum value is {tensor_vector.max()} at index {tensor_vector.argmax()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Argmin()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "        [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "        [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensor matrix above has the maximum value is 0 at index 0'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Tensor matrix above has the maximum value is {TENSOR_MATRIX.min()} at index {TENSOR_MATRIX.argmin()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "\n",
    "**Rules of thumbs when reshaping tensor**\n",
    "\n",
    "- *The tensor after reshaped must preserve the total number of elements*\n",
    "\n",
    "- *View the tensor in the different dimension arrangement*\n",
    "\n",
    "*Think of it like you flatten it first then you rearrange its dimension as you desired*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "         [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([3, 10])',\n",
       " '^',\n",
       " 'Total number of elements: 30')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX,    '^',f\"Shape: {TENSOR_MATRIX.shape}\", '^', f\"Total number of elements: {TENSOR_MATRIX.shape.numel()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 3, 7, 9, 1, 2],\n",
       "         [0, 7, 3, 0, 0, 9],\n",
       "         [8, 1, 3, 2, 5, 7],\n",
       "         [9, 2, 0, 3, 7, 6],\n",
       "         [1, 1, 7, 1, 4, 8]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([5, 6])',\n",
       " '^',\n",
       " 'Total number of elements: 30')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_reshaped = TENSOR_MATRIX.reshape(5,6)\n",
    "\n",
    "TENSOR_MATRIX_reshaped,    '^',f\"Shape: {TENSOR_MATRIX_reshaped.shape}\", '^', f\"Total number of elements: {TENSOR_MATRIX_reshaped.shape.numel()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0, 0, 9, 8, 1, 3, 2, 5, 7, 9, 2, 0, 3, 7, 6,\n",
       "          1, 1, 7, 1, 4, 8]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([1, 30])',\n",
       " '^',\n",
       " 'Total number of elements: 30')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_reshaped = TENSOR_MATRIX.reshape(1,30, )\n",
    "\n",
    "TENSOR_MATRIX_reshaped,    '^',f\"Shape: {TENSOR_MATRIX_reshaped.shape}\", '^', f\"Total number of elements: {TENSOR_MATRIX_reshaped.shape.numel()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 3, 7, 9, 1, 2]],\n",
       " \n",
       "         [[0, 7, 3, 0, 0, 9]],\n",
       " \n",
       "         [[8, 1, 3, 2, 5, 7]],\n",
       " \n",
       "         [[9, 2, 0, 3, 7, 6]],\n",
       " \n",
       "         [[1, 1, 7, 1, 4, 8]]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([5, 1, 6])',\n",
       " '^',\n",
       " 'Total number of elements: 30')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_reshaped = TENSOR_MATRIX.reshape(5, 1, 6)\n",
    "\n",
    "TENSOR_MATRIX_reshaped,    '^',f\"Shape: {TENSOR_MATRIX_reshaped.shape}\", '^', f\"Total number of elements: {TENSOR_MATRIX_reshaped.shape.numel()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "- *Stacking tensor mean duplicated the tensor on top of itself many times so that the result tensor obviously gain one more dimension (wrapping reasonably)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "         [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([3, 10])')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX, \"^\", f\"Shape: {TENSOR_MATRIX.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "          [0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "          [0, 3, 7, 9, 1, 2, 0, 7, 3, 0]],\n",
       " \n",
       "         [[0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "          [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "          [0, 9, 8, 1, 3, 2, 5, 7, 9, 2]],\n",
       " \n",
       "         [[0, 3, 7, 6, 1, 1, 7, 1, 4, 8],\n",
       "          [0, 3, 7, 6, 1, 1, 7, 1, 4, 8],\n",
       "          [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([3, 3, 10])')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_stacked = torch.stack([TENSOR_MATRIX, \n",
    "                                     TENSOR_MATRIX,\n",
    "                                     TENSOR_MATRIX], dim=1) # they're in the same size\n",
    "\n",
    "TENSOR_MATRIX_stacked, \"^\", f\"Shape: {TENSOR_MATRIX_stacked.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating\n",
    "\n",
    "    torch.cat((tensor_1,... tensor_2,) dim=0, **)\n",
    "\n",
    "**Key points when perform concatenating tensors:**\n",
    "\n",
    "- the tensors are using to concatenate must be in the same size\n",
    "\n",
    "*Find the rule yourself, I'm out*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Matrix concatenating*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "         [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]]),\n",
       " '^',\n",
       " 'Tensor dimension: 2',\n",
       " '^',\n",
       " 'Tensor shape: torch.Size([3, 10])')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX, \"^\", f\"Tensor dimension: {TENSOR_MATRIX.dim()}\", \"^\", f\"Tensor shape: {TENSOR_MATRIX.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*when set the **dim=1** these two tensors is concatenated horizontally*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "         [0, 3, 7, 6, 1, 1, 7, 1, 4, 8],\n",
       "         [0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "         [0, 3, 7, 6, 1, 1, 7, 1, 4, 8],\n",
       "         [0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "         [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([9, 10])')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_con = torch.cat((TENSOR_MATRIX, TENSOR_MATRIX, TENSOR_MATRIX), dim=0)\n",
    "TENSOR_MATRIX_con, \"^\", f\"Shape: {TENSOR_MATRIX_con.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*when set the **dim=0** these two tensors above is concatenated vertically*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0, 0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 9, 8, 1, 3, 2, 5, 7, 9, 2, 0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "         [0, 3, 7, 6, 1, 1, 7, 1, 4, 8, 0, 3, 7, 6, 1, 1, 7, 1, 4, 8]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([3, 20])')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_con = torch.concat((TENSOR_MATRIX, TENSOR_MATRIX,), dim=1)\n",
    "TENSOR_MATRIX_con, \"^\", f\"Shape: {TENSOR_MATRIX_con.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Multi-dimensional Tensor concatenating*\n",
    "\n",
    "**The rule:**\n",
    "- The concatenated tensor is computed by adding all the dim of those tensors \n",
    "\n",
    "        tensor_2x3x5 concat(dim=0) tensor_2x3x5 = tensor_4x3x5\n",
    "        tensor_2x3x5 concat(dim=1) tensor_2x3x5 = tensor_2x6x5\n",
    "        tensor_2x3x5 concat(dim=2) tensor_2x3x5 = tensor_2x3x10\n",
    "        \n",
    "*How easy it is*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5779, 0.1591, 0.9498, 0.3779, 0.8012],\n",
       "         [0.0357, 0.6562, 0.0634, 0.9714, 0.8872],\n",
       "         [0.8116, 0.0194, 0.1223, 0.5584, 0.3756]],\n",
       "\n",
       "        [[0.5161, 0.8385, 0.5450, 0.2283, 0.0072],\n",
       "         [0.3512, 0.7032, 0.4121, 0.2701, 0.9033],\n",
       "         [0.8857, 0.4125, 0.6010, 0.3538, 0.6253]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2x3x5 = torch.rand(2,3,5)\n",
    "tensor_2x3x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5779, 0.1591, 0.9498, 0.3779, 0.8012],\n",
       "          [0.0357, 0.6562, 0.0634, 0.9714, 0.8872],\n",
       "          [0.8116, 0.0194, 0.1223, 0.5584, 0.3756]],\n",
       " \n",
       "         [[0.5161, 0.8385, 0.5450, 0.2283, 0.0072],\n",
       "          [0.3512, 0.7032, 0.4121, 0.2701, 0.9033],\n",
       "          [0.8857, 0.4125, 0.6010, 0.3538, 0.6253]],\n",
       " \n",
       "         [[0.5779, 0.1591, 0.9498, 0.3779, 0.8012],\n",
       "          [0.0357, 0.6562, 0.0634, 0.9714, 0.8872],\n",
       "          [0.8116, 0.0194, 0.1223, 0.5584, 0.3756]],\n",
       " \n",
       "         [[0.5161, 0.8385, 0.5450, 0.2283, 0.0072],\n",
       "          [0.3512, 0.7032, 0.4121, 0.2701, 0.9033],\n",
       "          [0.8857, 0.4125, 0.6010, 0.3538, 0.6253]]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([4, 3, 5])')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_4x3x5 = torch.concat((tensor_2x3x5, tensor_2x3x5), dim=0 )\n",
    "tensor_4x3x5, \"^\",  f\"Shape: {tensor_4x3x5.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5779, 0.1591, 0.9498, 0.3779, 0.8012],\n",
       "          [0.0357, 0.6562, 0.0634, 0.9714, 0.8872],\n",
       "          [0.8116, 0.0194, 0.1223, 0.5584, 0.3756],\n",
       "          [0.5779, 0.1591, 0.9498, 0.3779, 0.8012],\n",
       "          [0.0357, 0.6562, 0.0634, 0.9714, 0.8872],\n",
       "          [0.8116, 0.0194, 0.1223, 0.5584, 0.3756]],\n",
       " \n",
       "         [[0.5161, 0.8385, 0.5450, 0.2283, 0.0072],\n",
       "          [0.3512, 0.7032, 0.4121, 0.2701, 0.9033],\n",
       "          [0.8857, 0.4125, 0.6010, 0.3538, 0.6253],\n",
       "          [0.5161, 0.8385, 0.5450, 0.2283, 0.0072],\n",
       "          [0.3512, 0.7032, 0.4121, 0.2701, 0.9033],\n",
       "          [0.8857, 0.4125, 0.6010, 0.3538, 0.6253]]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([2, 6, 5])')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2x6x5 = torch.concat((tensor_2x3x5, tensor_2x3x5), dim=1 )\n",
    "tensor_2x6x5, \"^\",  f\"Shape: {tensor_2x6x5.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5779, 0.1591, 0.9498, 0.3779, 0.8012, 0.5779, 0.1591, 0.9498,\n",
       "           0.3779, 0.8012],\n",
       "          [0.0357, 0.6562, 0.0634, 0.9714, 0.8872, 0.0357, 0.6562, 0.0634,\n",
       "           0.9714, 0.8872],\n",
       "          [0.8116, 0.0194, 0.1223, 0.5584, 0.3756, 0.8116, 0.0194, 0.1223,\n",
       "           0.5584, 0.3756]],\n",
       " \n",
       "         [[0.5161, 0.8385, 0.5450, 0.2283, 0.0072, 0.5161, 0.8385, 0.5450,\n",
       "           0.2283, 0.0072],\n",
       "          [0.3512, 0.7032, 0.4121, 0.2701, 0.9033, 0.3512, 0.7032, 0.4121,\n",
       "           0.2701, 0.9033],\n",
       "          [0.8857, 0.4125, 0.6010, 0.3538, 0.6253, 0.8857, 0.4125, 0.6010,\n",
       "           0.3538, 0.6253]]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([2, 3, 10])')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_4x3x10 = torch.concat((tensor_2x3x5, tensor_2x3x5), dim=2 )\n",
    "tensor_4x3x10, \"^\",  f\"Shape: {tensor_4x3x10.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezing\n",
    "\n",
    "- *How about removing all single dimensions from a tensor?*\n",
    "\n",
    "***Eg.***\n",
    "\n",
    "    torch.Size([1, 1, 4, 5, 1]) => squeezed => torch.Size([4, 5])\n",
    "\n",
    "*Easy to comprehend, right!*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[[0.4947],\n",
       "            [0.0709],\n",
       "            [0.6561],\n",
       "            [0.9767],\n",
       "            [0.3276]],\n",
       " \n",
       "           [[0.2643],\n",
       "            [0.3453],\n",
       "            [0.2028],\n",
       "            [0.0101],\n",
       "            [0.3845]],\n",
       " \n",
       "           [[0.1698],\n",
       "            [0.6623],\n",
       "            [0.9199],\n",
       "            [0.2478],\n",
       "            [0.4083]],\n",
       " \n",
       "           [[0.0742],\n",
       "            [0.1514],\n",
       "            [0.5069],\n",
       "            [0.5581],\n",
       "            [0.1320]]]]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([1, 1, 4, 5, 1])')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tensor = torch.rand(size=(1,1,4,5,1), dtype=torch.float32) # make an example\n",
    "\n",
    "temp_tensor,  \"^\", f\"Shape: {temp_tensor.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4947, 0.0709, 0.6561, 0.9767, 0.3276],\n",
       "         [0.2643, 0.3453, 0.2028, 0.0101, 0.3845],\n",
       "         [0.1698, 0.6623, 0.9199, 0.2478, 0.4083],\n",
       "         [0.0742, 0.1514, 0.5069, 0.5581, 0.1320]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([4, 5])')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tensor_squeezed = temp_tensor.squeeze()\n",
    "\n",
    "temp_tensor_squeezed,   \"^\", f\"Shape: {temp_tensor_squeezed.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "- *indexing values goes outer dimension -> inner dimension (through the square bracket)*\n",
    "\n",
    "        Using tensor[idx_dim1][idx_dim2][idx_dim3][...] when perform indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "          [0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "          [0, 3, 7, 9, 1, 2, 0, 7, 3, 0]],\n",
       " \n",
       "         [[0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "          [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "          [0, 9, 8, 1, 3, 2, 5, 7, 9, 2]],\n",
       " \n",
       "         [[0, 3, 7, 6, 1, 1, 7, 1, 4, 8],\n",
       "          [0, 3, 7, 6, 1, 1, 7, 1, 4, 8],\n",
       "          [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([3, 3, 10])')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_stacked, \"^\", f\"Shape: {TENSOR_MATRIX_stacked.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 3, 7, 9, 1, 2, 0, 7, 3, 0]]),\n",
       " '^',\n",
       " 'Shape: torch.Size([3, 10])')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_stacked[0], \"^\", f\"Shape: {TENSOR_MATRIX_stacked[0].shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0]), '^', 'Shape: torch.Size([10])')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_stacked[0][1] , \"^\", f\"Shape: {TENSOR_MATRIX_stacked[0][1].shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7), '^', 'Shape: torch.Size([])')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_stacked[0][1][2] , \"^\", f\"Shape: {TENSOR_MATRIX_stacked[0][1][2].shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "\n",
    "- Slicing when we want to slice the tensor in a specific range or dimension\n",
    "\n",
    "        Using tensor[idx_start_dim1: idx_end_dim1: idx_step_dim1,  idx_start_dim2: idx_end_dim2: idx_step_dim2, ...] when slicing\n",
    "\n",
    "Note: tensor can be only slice in a finite time, limited by the tensor dimension\n",
    "\n",
    "If you want to make more slicing, then make it in a new square bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 3, 7, 9, 1, 2, 0, 7, 3, 0],\n",
       "         [0, 3, 7, 9, 1, 2, 0, 7, 3, 0]],\n",
       "\n",
       "        [[0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "         [0, 9, 8, 1, 3, 2, 5, 7, 9, 2],\n",
       "         [0, 9, 8, 1, 3, 2, 5, 7, 9, 2]],\n",
       "\n",
       "        [[0, 3, 7, 6, 1, 1, 7, 1, 4, 8],\n",
       "         [0, 3, 7, 6, 1, 1, 7, 1, 4, 8],\n",
       "         [0, 3, 7, 6, 1, 1, 7, 1, 4, 8]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*trying to internalize this move, you're the one who fucking made it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_MATRIX_stacked[0:2, 0, 1: 5][0:2, 1][1] # limitation of slicing times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor vs Numpy\n",
    "\n",
    "**Using these two method to transform a numpy array into tensor pytorch and vice versa**\n",
    "\n",
    "    torch.from_numpy(ndarray) :  Numpy array    -> Pytorch Tensor\n",
    "    torch.Tensor.numpy()      :  Pytorch Tensor -> Numpy array\n",
    "\n",
    "*Note: the transformation have no affection on the data type itself*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 3, 7, 9, 1, 2, 0, 7, 3, 0]), dtype('int64'))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.array([0,3,7,9,1,2,0,7,3,0])\n",
    "ndarray, ndarray.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *ndarray to tensor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 3, 7, 9, 1, 2, 0, 7, 3, 0]), torch.int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_array = torch.from_numpy(ndarray)\n",
    "tensor_array, tensor_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *tensor to ndarray*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 3, 7, 9, 1, 2, 0, 7, 3, 0]), dtype('int64'))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndarray = tensor_array.numpy()\n",
    "ndarray, ndarray.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproducibility with reset RANDOM_SEED\n",
    "RANDOM_SEED = 16\n",
    "\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_A = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproducibility without reset RANDOM_SEED\n",
    "RANDOM_SEED = 16\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing GPU as computational unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if cuda was installed on this device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If device is cuda that mean Pytorch can see the GPU(Nvidia) on your computer and you can utilize its computational power for good*\n",
    "\n",
    "#### *device(type=cuda) ~ Nvidia GPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  16,   10, 2004],\n",
       "          [   9,    3, 1986],\n",
       "          [   3,   12, 2007],\n",
       "          [  20,    7, 2010],\n",
       "          [   4,    1, 2004]]]),\n",
       " '^',\n",
       " 'Device: cpu')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor, \"^\", f\"Device: {tensor.device}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Moving tensor to the gpu (if available)*\n",
    "\n",
    "*Copying the tensor to the gpu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  16,   10, 2004],\n",
       "          [   9,    3, 1986],\n",
       "          [   3,   12, 2007],\n",
       "          [  20,    7, 2010],\n",
       "          [   4,    1, 2004]]], device='cuda:0'),\n",
       " '^',\n",
       " 'Device: cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu, \"^\", f\"Device: {tensor_on_gpu.device}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Moving tensor back to CPU*\n",
    "\n",
    "*Returning a copy of tensor in gpu to cpu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  16,   10, 2004],\n",
       "          [   9,    3, 1986],\n",
       "          [   3,   12, 2007],\n",
       "          [  20,    7, 2010],\n",
       "          [   4,    1, 2004]]]),\n",
       " '^',\n",
       " 'Device: cpu')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_cpu = tensor_on_gpu.cpu()\n",
    "\n",
    "tensor_on_cpu, \"^\", f\"Device: {tensor_on_cpu.device}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The original tensor in gpu stay there the same*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  16,   10, 2004],\n",
       "          [   9,    3, 1986],\n",
       "          [   3,   12, 2007],\n",
       "          [  20,    7, 2010],\n",
       "          [   4,    1, 2004]]], device='cuda:0'),\n",
       " '^',\n",
       " 'Device: cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu, \"^\", f\"Device: {tensor_on_gpu.device}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network\n",
    "\n",
    "*Neural nets are full of matrix multiplications and dot products*\n",
    "\n",
    "The ***torch.nn.Linear()*** module also known as a feed-forward layer or fully connected layer, implement a matrix multiplication between an input matrix **x** and a weights matrix **A**\n",
    "\n",
    "        \n",
    "        y = x @ A.T + b\n",
    "\n",
    "##### ***Where***\n",
    "\n",
    "- **x** is the input to the layer (deep learning is the stack of layers like ***torch.nn.Linear())*** and other on top of each other\n",
    "- **A** is the weights matrix created by the layer, this matrix starts out as random numbers that get neural nets learn to better  represents pattern in data\n",
    "- *.T* is represented for a transposed matrix, because the weights matrix get transposed\n",
    "- **b** is the bias term used to slightly offset the weights and the input\n",
    "- **y** is the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.7211, -1.5712, -1.6104,  0.6170,  2.7666, -0.3493],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " '^',\n",
       " 'Shape: torch.Size([6])')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(16)\n",
    "\n",
    "# Linear layer perform matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=10,    # in_feature  = matches inner dimension of input matrix\n",
    "                         out_features=6)   # out feature = describes outer value\n",
    "\n",
    "x = tensor_vector.type(torch.float32)\n",
    "output = linear(x)\n",
    "\n",
    "output, \"^\", f\"Shape: {output.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *input shape = (1,10)* \n",
    "- *output shape = (10, 6)*\n",
    "\n",
    "        (1, 10) * (10,6) = (1,6)\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the exercises are focused on practicing the code above.\n",
    "\n",
    "You should be able to complete them by referencing each section or by following the resource(s) linked.\n",
    "\n",
    "\n",
    "1. Documentation reading - A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation on torch.Tensor and for torch.cuda.\n",
    "2. Create a random tensor with shape (7, 7).\n",
    "3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor).\n",
    "4. Set the random seed to 0 and do exercises 2 & 3 over again.\n",
    "5. Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one). If there is, set the GPU random seed to 1234.\n",
    "6. Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed).\n",
    "7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
    "8. Find the maximum and minimum values of the output of 7.\n",
    "9. Find the maximum and minimum index values of the output of 7.\n",
    "10. Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n",
    "\n",
    "**Extra-curriculum**\n",
    "\n",
    "    *Spend 1-hour going through the PyTorch basics tutorial (I'd recommend the Quickstart and Tensors sections).\n",
    "    To learn more on how a tensor can represent data, see this video: What's a tensor?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3663, 0.2344, 0.4978, 0.9769, 0.8070, 0.2074, 0.2312],\n",
       "        [0.2481, 0.6315, 0.6485, 0.4123, 0.1299, 0.9386, 0.7432],\n",
       "        [0.4514, 0.7183, 0.9324, 0.3358, 0.7483, 0.0794, 0.9697],\n",
       "        [0.8907, 0.2126, 0.1475, 0.4472, 0.4347, 0.8528, 0.6217],\n",
       "        [0.5016, 0.5251, 0.0743, 0.4651, 0.1498, 0.6331, 0.2403],\n",
       "        [0.6683, 0.7104, 0.2131, 0.8983, 0.2129, 0.9838, 0.7356],\n",
       "        [0.0420, 0.2532, 0.5681, 0.8978, 0.5465, 0.1709, 0.5687]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.\n",
    "2.\n",
    "tensor_7_7 = torch.rand(size=(7,7))\n",
    "tensor_7_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0542],\n",
       "        [2.5098],\n",
       "        [3.3411],\n",
       "        [2.4096],\n",
       "        [1.6466],\n",
       "        [2.8574],\n",
       "        [1.9666]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.\n",
    "ran_tensor_1_7 = torch.rand(size=(1,7))\n",
    "ran_tensor_1_7\n",
    "\n",
    "tensor_7_7 @ ran_tensor_1_7.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8542],\n",
       "        [1.9611],\n",
       "        [2.2884],\n",
       "        [3.0481],\n",
       "        [1.7067],\n",
       "        [2.5290],\n",
       "        [1.7989]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4. \n",
    "RANDOM_SEED = 0\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "tensor_7_7 = torch.rand(size=(7,7))\n",
    "ran_tensor_1_7 = torch.rand(size=(1,7))\n",
    "\n",
    "tensor_7_7 @ ran_tensor_1_7.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1272, 0.8167, 0.5440],\n",
       "         [0.6601, 0.2721, 0.9737]], device='cuda:0'),\n",
       " '^',\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5. \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "RANDOM_SEED = 1234\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "tensor_2x3_gpu = torch.rand(size=(2,3), device=device)\n",
    "tensor_2x3_gpu, \"^\", tensor_2x3_gpu.device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5932, 0.1123, 0.1535],\n",
       "         [0.2417, 0.7262, 0.7011]], device='cuda:0'),\n",
       " '^',\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6. \n",
    "tensor_2x3_cpu_ran_f = torch.rand(size=(2,3))\n",
    "tensor_2x3_cpu_ran_s = torch.rand(size=(2,3))\n",
    "\n",
    "tensor_2x3_gpu_ran_f = tensor_2x3_cpu_ran_f.to(device=device)\n",
    "tensor_2x3_gpu_ran_s = tensor_2x3_cpu_ran_s.to(device=device)\n",
    "\n",
    "tensor_2x3_gpu_ran_f, \"^\", tensor_2x3_gpu_ran_f.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3129, 0.4120],\n",
       "        [1.0651, 0.9143]], device='cuda:0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7. \n",
    "tensor_result = tensor_2x3_gpu_ran_f @ tensor_2x3_gpu_ran_s.T\n",
    "tensor_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3129, device='cuda:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8. \n",
    "tensor_result.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0651, device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9.1\n",
    "tensor_result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6761, device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9.2 \n",
    "tensor_result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.2188,  0.2590, -1.0297, -0.5008,  0.2734, -0.9181, -0.0404,\n",
       "            0.2881, -0.0075, -0.9145]]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10. \n",
    "tensor_ran = torch.randn(size=(1,1,1,10))\n",
    "tensor_ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2188,  0.2590, -1.0297, -0.5008,  0.2734, -0.9181, -0.0404,  0.2881,\n",
       "        -0.0075, -0.9145])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ran_squeezed = tensor_ran.squeeze()\n",
    "tensor_ran_squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ran_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
